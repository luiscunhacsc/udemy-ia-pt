{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvzkJieZYCto"
      },
      "source": [
        "# Test of updated model with more convolutional layers and batch normalization *and* rate scheduling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK-ODiiwYCtp"
      },
      "source": [
        "We'll be using Keras with TensorFlow backend to build a skin lesion classifier. Let's start by importing the necessary libraries and setting up the directory structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL4GT4P6YCtq",
        "outputId": "2eca0ced-6689-4b69-e1c3-2f73425537d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 6658607540581434994\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14328594432\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 14292241233268128767\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "#%pip install tensorflow\n",
        "#%pip install keras\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGa0wFepYCtq"
      },
      "source": [
        "Next, import the necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSgoRn9eYCtq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zs0pH65jYJhG"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import requests\n",
        "\n",
        "# URLs of the file chunks on GitHub\n",
        "urls = [\n",
        "    \"https://github.com/luiscunhacsc/course_dl_datasets/blob/main/SkinDataSet.zip.001?raw=true\",\n",
        "    \"https://github.com/luiscunhacsc/course_dl_datasets/blob/main/SkinDataSet.zip.002?raw=true\",\n",
        "    \"https://github.com/luiscunhacsc/course_dl_datasets/blob/main/SkinDataSet.zip.003?raw=true\",\n",
        "    \"https://github.com/luiscunhacsc/course_dl_datasets/blob/main/SkinDataSet.zip.004?raw=true\",\n",
        "    \"https://github.com/luiscunhacsc/course_dl_datasets/blob/main/SkinDataSet.zip.005?raw=true\",\n",
        "    \"https://github.com/luiscunhacsc/course_dl_datasets/blob/main/SkinDataSet.zip.006?raw=true\",\n",
        "    \"https://github.com/luiscunhacsc/course_dl_datasets/blob/main/SkinDataSet.zip.007?raw=true\",\n",
        "]\n",
        "\n",
        "# Download and combine the chunks\n",
        "with open('combined_file.zip', 'wb') as output_file:\n",
        "    for url in urls:\n",
        "        response = requests.get(url, allow_redirects=True)\n",
        "        output_file.write(response.content)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "!unzip -q combined_file.zip\n",
        "!rm combined_file.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yJw3ItXYCtr"
      },
      "source": [
        "Now, let's define some parameters and directory paths:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpzL6m-8YCtr"
      },
      "outputs": [],
      "source": [
        "img_width, img_height = 224, 224\n",
        "train_data_dir = 'skin_train_dataset'\n",
        "test_data_dir = 'skin_test_dataset'\n",
        "nb_train_samples = 3297\n",
        "epochs = 50\n",
        "batch_size = 32\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QV3U9-i1YCtr"
      },
      "outputs": [],
      "source": [
        "#This code is only needed if the images are all in the same folder\n",
        "#(i.e. not divided into \"benign\" and \"malignant\" subfolders)\n",
        "\n",
        "#import os\n",
        "#import shutil\n",
        "\n",
        "#src_dir = 'skin_dataset_26mar2023'\n",
        "#benign_dir = os.path.join(src_dir, 'benign')\n",
        "#malignant_dir = os.path.join(src_dir, 'malignant')\n",
        "\n",
        "# Create the subfolders if they don't exist\n",
        "#os.makedirs(benign_dir, exist_ok=True)\n",
        "#os.makedirs(malignant_dir, exist_ok=True)\n",
        "\n",
        "# Move the benign and malignant images to their respective subfolders\n",
        "#for filename in os.listdir(src_dir):\n",
        "#    src_path = os.path.join(src_dir, filename)\n",
        "#\n",
        "#    if os.path.isfile(src_path):\n",
        "#        if filename.startswith('benign'):\n",
        "#            shutil.move(src_path, os.path.join(benign_dir, filename))\n",
        "#        elif filename.startswith('malignant'):\n",
        "#            shutil.move(src_path, os.path.join(malignant_dir, filename))\n",
        "\n",
        "\n",
        "#src_dir = 'test_dataset_26mar2023'\n",
        "#benign_dir = os.path.join(src_dir, 'benign')\n",
        "#malignant_dir = os.path.join(src_dir, 'malignant')\n",
        "\n",
        "# Create the subfolders if they don't exist\n",
        "#os.makedirs(benign_dir, exist_ok=True)\n",
        "#os.makedirs(malignant_dir, exist_ok=True)\n",
        "\n",
        "# Move the benign and malignant images to their respective subfolders\n",
        "#for filename in os.listdir(src_dir):\n",
        "#    src_path = os.path.join(src_dir, filename)\n",
        "#\n",
        "#    if os.path.isfile(src_path):\n",
        "#        if filename.startswith('benign'):\n",
        "#            shutil.move(src_path, os.path.join(benign_dir, filename))\n",
        "#        elif filename.startswith('malignant'):\n",
        "#            shutil.move(src_path, os.path.join(malignant_dir, filename))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBIAh17hYCtr"
      },
      "source": [
        "Depending on the image format, you may need to set the input shape for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM5sOQL0YCts"
      },
      "outputs": [],
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHaGA4MtYCts"
      },
      "source": [
        "Model architecture using the Keras functional API:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyzpXD6NYCts"
      },
      "source": [
        "Test of updated model with more convolutional layers and batch normalization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ejWkUP_YCts"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = Input(shape=input_shape)\n",
        "\n",
        "# Create the convolutional and pooling layers\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
        "bn1 = BatchNormalization()(conv1)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n",
        "\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu')(pool1)\n",
        "bn2 = BatchNormalization()(conv2)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n",
        "\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu')(pool2)\n",
        "bn3 = BatchNormalization()(conv3)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n",
        "\n",
        "conv4 = Conv2D(256, (3, 3), activation='relu')(pool3)\n",
        "bn4 = BatchNormalization()(conv4)\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n",
        "\n",
        "conv5 = Conv2D(512, (3, 3), activation='relu')(pool4)\n",
        "bn5 = BatchNormalization()(conv5)\n",
        "pool5 = MaxPooling2D(pool_size=(2, 2))(bn5)\n",
        "\n",
        "# Flatten the output of the last pooling layer\n",
        "flat = Flatten()(pool5)\n",
        "\n",
        "# Create the dense layers\n",
        "dense1 = Dense(64, activation='relu')(flat)\n",
        "dropout = Dropout(0.5)(dense1)\n",
        "output_layer = Dense(1, activation='sigmoid')(dropout)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb9Zll27YCts"
      },
      "source": [
        "Training, validation and test data sets generators\n",
        "Note that you can control for **data augmentation** usage\n",
        "Data augmentation is only done in the training data set\n",
        "You control that option by setting __use_data_augmentation__ to True or False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efxRyhYGYCtt",
        "outputId": "f4c2b113-1ed1-4515-83e5-86b881653596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Directories:\n",
            "Train: skin_train_dataset\n",
            "Test: skin_test_dataset\n",
            "Found 2478 images belonging to 2 classes.\n",
            "Found 619 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "print(\"Using Directories:\")\n",
        "print(\"Train:\", train_data_dir)\n",
        "print(\"Test:\", test_data_dir)\n",
        "\n",
        "use_data_augmentation = True\n",
        "\n",
        "if not use_data_augmentation:\n",
        "    train_datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2)\n",
        "else:\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1. / 255,\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        brightness_range=[0.5, 1.5],\n",
        "        channel_shift_range=20,\n",
        "        fill_mode='nearest',\n",
        "        validation_split=0.2)\n",
        "\n",
        "# Training generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='training')\n",
        "\n",
        "# Validation generator (augmented)\n",
        "validation_datagen = train_datagen\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='validation')\n",
        "\n",
        "# Test data generator (non-augmented)\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_width,img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqSd7r92YCtt"
      },
      "source": [
        "Evaluate the model on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOv3-mC2YCtu",
        "outputId": "3acaf76d-83a1-44cb-a715-56d39d8c054b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 9s 111ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Test accuracy: 50.00%\n"
          ]
        }
      ],
      "source": [
        "test_scores = model.evaluate(test_generator, verbose=1)\n",
        "print(\"Test accuracy: %.2f%%\" % (test_scores[1] * 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skrhCYqSYCtu"
      },
      "source": [
        "Create a ModelCheckpoint instance and specify the file path, the metric to monitor, and the mode (maximize or minimize the metric):\n",
        "\n",
        "This code will save the best model based on the validation accuracy during training.\n",
        "The save_best_only=True argument ensures that only the model with the best performance so far is saved.\n",
        "Note that the file \"best_skin_lesion_classifier.h5\" will be overwritten whenever a better model is found during training.\n",
        "The verbose=1 argument provides updates whenever a new best model is saved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODsKbGiCYCtu"
      },
      "outputs": [],
      "source": [
        "checkpoint_filepath = 'best_skin_lesion_classifier.h5'\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga_v2_73YCtu"
      },
      "source": [
        "This callback will monitor a specified metric (usually validation loss or accuracy) and stop training when the metric\n",
        "does not improve for a given number of consecutive epochs. This helps to avoid overfitting and reduce training time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNqrm963YCtu"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnJm9VmUYCtv"
      },
      "source": [
        "Add learning rate scheduling (note that the patience for early stopping has to be changes in a way compatible to the patience in the LRS callback):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UPnEfa9YCtv"
      },
      "outputs": [],
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_lr=1e-6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IRQ9-LVYCtv"
      },
      "source": [
        "Train the model using the fit method and retain the training history:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63NKS-XbYCtv",
        "outputId": "6312035e-3d8d-4725-bb2e-dad4b125ac16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "77/77 [==============================] - ETA: 0s - loss: 1.2297 - accuracy: 0.6333\n",
            "Epoch 1: val_accuracy improved from -inf to 0.56414, saving model to best_skin_lesion_classifier_28mar_4.h5\n",
            "77/77 [==============================] - 74s 862ms/step - loss: 1.2297 - accuracy: 0.6333 - val_loss: 1.0963 - val_accuracy: 0.5641 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "51/77 [==================>...........] - ETA: 14s - loss: 0.7386 - accuracy: 0.6797"
          ]
        }
      ],
      "source": [
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "validation_steps = validation_generator.samples // validation_generator.batch_size\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[model_checkpoint, early_stopping, reduce_lr])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4Bm5QYOYCtv"
      },
      "source": [
        "Evaluate the model on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjhsQdydYCtv"
      },
      "outputs": [],
      "source": [
        "test_scores = model.evaluate(test_generator, verbose=1)\n",
        "print(\"Test accuracy: %.2f%%\" % (test_scores[1] * 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te1iHldqYCtv"
      },
      "source": [
        "Evaluate the model on the validation and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ly32h_1YCtv"
      },
      "outputs": [],
      "source": [
        "# Validation set\n",
        "validation_scores = model.evaluate(validation_generator, verbose=1)\n",
        "print(\"Validation accuracy: %.2f%%\" % (validation_scores[1] * 100))\n",
        "\n",
        "# Test set\n",
        "test_scores = model.evaluate(test_generator, verbose=1)\n",
        "print(\"Test accuracy: %.2f%%\" % (test_scores[1] * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjuyFtmjYCtw"
      },
      "source": [
        "Make predictions and compare them to the true labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OksP2syYCtw"
      },
      "outputs": [],
      "source": [
        "# Predictions for test set\n",
        "predictions = model.predict(test_generator)\n",
        "predicted_classes = np.round(predictions)  # Round predictions to obtain class labels\n",
        "\n",
        "# Get true labels\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "# Compare predicted_classes and\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFUXHwyvYCtw"
      },
      "source": [
        "With this implementation, you can train your model, and the best version will be saved based on the highest validation accuracy observed during training.\n",
        "Once the training is finished, you can load the best model using the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qei9eWIKYCtw"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "best_model = load_model('best_skin_lesion_classifier.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sje0BZNGYCtw"
      },
      "source": [
        "You can then evaluate the performance of the best model on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-zbc_MsYCtw"
      },
      "outputs": [],
      "source": [
        "test_scores = best_model.evaluate(test_generator, verbose=1)\n",
        "print(\"Test accuracy: %.2f%%\" % (test_scores[1] * 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Zp5AF19YCtw"
      },
      "source": [
        "Plot training history:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FotE_m1JYCtw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_history(history):\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy', color='white')\n",
        "    plt.xlabel('Epoch', color='white')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.tick_params(axis='both', colors='white')  # Added this line\n",
        "    plt.show()\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss', color='white')\n",
        "    plt.xlabel('Epoch', color='white')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.tick_params(axis='both', colors='white')  # Added this line\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
