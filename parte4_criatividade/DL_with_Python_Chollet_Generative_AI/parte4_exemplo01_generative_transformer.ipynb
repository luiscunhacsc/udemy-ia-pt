{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luiscunhacsc/udemy-ia-pt/blob/main/parte4_criatividade/DL_with_Python_Chollet_Generative_AI/parte4_exemplo01_generative_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBJfu3Hr06IN"
      },
      "source": [
        "## Generative Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Um-d8xv06IP"
      },
      "source": [
        "Código de François Chollet / Code by Francois Chollet *\n",
        "* Chollet, F. (2021). Deep Learning with Python. Manning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl1BVeNw06IQ"
      },
      "source": [
        "### Implementing text generation with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keen4u1t06IQ"
      },
      "source": [
        "#### Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj39U6YA06IQ"
      },
      "source": [
        "**Downloading and uncompressing the IMDB movie reviews dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "n7jKj-lF06IR",
        "outputId": "cc27376f-e149-401e-dc4c-0ead998bd863",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-15 16:33:36--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz.1’\n",
            "\n",
            "aclImdb_v1.tar.gz.1 100%[===================>]  80.23M  48.2MB/s    in 1.7s    \n",
            "\n",
            "2024-05-15 16:33:38 (48.2 MB/s) - ‘aclImdb_v1.tar.gz.1’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFnHNOri06IR"
      },
      "source": [
        "**Creating a dataset from text files (one file = one sample)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "athe4alr06IS",
        "outputId": "77ff46de-87bf-44c4-df68-7bdfe649b084",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100006 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "dataset = keras.utils.text_dataset_from_directory(\n",
        "    directory=\"aclImdb\", label_mode=None, batch_size=256)\n",
        "dataset = dataset.map(lambda x: tf.strings.regex_replace(x, \"<br />\", \" \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxE7uvLU06IS"
      },
      "source": [
        "**Preparing a `TextVectorization` layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wLjqlqfi06IU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "sequence_length = 100\n",
        "vocab_size = 15000\n",
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "text_vectorization.adapt(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUofgSpp06IU"
      },
      "source": [
        "**Setting up a language modeling dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Xc5VDcQy06IU"
      },
      "outputs": [],
      "source": [
        "def prepare_lm_dataset(text_batch):\n",
        "    vectorized_sequences = text_vectorization(text_batch)\n",
        "    x = vectorized_sequences[:, :-1]\n",
        "    y = vectorized_sequences[:, 1:]\n",
        "    return x, y\n",
        "\n",
        "lm_dataset = dataset.map(prepare_lm_dataset, num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ7hA4Gw06IU"
      },
      "source": [
        "#### A Transformer-based sequence-to-sequence model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bIAwXhJp06IU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEmbedding, self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "          num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "          num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(TransformerDecoder, self).get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(\n",
        "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        else:\n",
        "            padding_mask = mask\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTMzrhTS06IU"
      },
      "source": [
        "**A simple Transformer-based language model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "n1EfWgC506IU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 2\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, x)\n",
        "outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7rn7CjX06IU"
      },
      "source": [
        "### A text-generation callback with variable-temperature sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki0cPS4G06IU"
      },
      "source": [
        "**The text-generation callback**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PiXak3vN06IU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "tokens_index = dict(enumerate(text_vectorization.get_vocabulary()))\n",
        "\n",
        "def sample_next(predictions, temperature=1.0):\n",
        "    predictions = np.asarray(predictions).astype(\"float64\")\n",
        "    predictions = np.log(predictions) / temperature\n",
        "    exp_preds = np.exp(predictions)\n",
        "    predictions = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, predictions, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "class TextGenerator(keras.callbacks.Callback):\n",
        "    def __init__(self,\n",
        "                 prompt,\n",
        "                 generate_length,\n",
        "                 model_input_length,\n",
        "                 temperatures=(1.,),\n",
        "                 print_freq=1):\n",
        "        self.prompt = prompt\n",
        "        self.generate_length = generate_length\n",
        "        self.model_input_length = model_input_length\n",
        "        self.temperatures = temperatures\n",
        "        self.print_freq = print_freq\n",
        "        vectorized_prompt = text_vectorization([prompt])[0].numpy()\n",
        "        self.prompt_length = np.nonzero(vectorized_prompt == 0)[0][0]\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % self.print_freq != 0:\n",
        "            return\n",
        "        for temperature in self.temperatures:\n",
        "            print(\"== Generating with temperature\", temperature)\n",
        "            sentence = self.prompt\n",
        "            for i in range(self.generate_length):\n",
        "                tokenized_sentence = text_vectorization([sentence])\n",
        "                predictions = self.model(tokenized_sentence)\n",
        "                next_token = sample_next(\n",
        "                    predictions[0, self.prompt_length - 1 + i, :]\n",
        "                )\n",
        "                sampled_token = tokens_index[next_token]\n",
        "                sentence += \" \" + sampled_token\n",
        "            print(sentence)\n",
        "\n",
        "prompt = \"This movie\"\n",
        "text_gen_callback = TextGenerator(\n",
        "    prompt,\n",
        "    generate_length=50,\n",
        "    model_input_length=sequence_length,\n",
        "    temperatures=(0.2, 0.5, 0.7, 1., 1.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n1QP2ky06IW"
      },
      "source": [
        "**Fitting the language model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FGUq7VRl06IW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0367dcd9-3a19-41e4-f03e-c76f36eb8b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 5.9244== Generating with temperature 0.2\n",
            "This movie was expecting much paid in big fan of driving 2 that the films the best 2 school jobs as acting is no will dilemma may be replaced by amazing refrain theme direction rising roger accident [UNK] is probably where almost worst of the [UNK] ive ever to kill and this\n",
            "== Generating with temperature 0.5\n",
            "This movie was terrible every but it was a lifetime of never been looking banal blonde pieces for violence and its time at hong kong parents im little more detective plays a bars problems but et sadly actually a hidden as a couple made me four scene in the crap 25 people\n",
            "== Generating with temperature 0.7\n",
            "This movie has one of how many times premise theres no wonder how i enjoyed godfather understated hits dubbed brash kudos to which the nonsense im glad it happens and exciting dark is very psychiatrist by many people [UNK] but it is obviously the beaten larry waste of james murdered a five\n",
            "== Generating with temperature 1.0\n",
            "This movie really doesnt really kind of its african race of a hero forensic action in taken on this fall out they were also very diaz in james meets both comedy student pictures i [UNK] for anything and frustrating because this babysitting and it was sad teacher around without being really know\n",
            "== Generating with temperature 1.5\n",
            "This movie is how accurate me of my heart out movie but you have been a fan its a film is excellent actresses in basement about one of time track as the a stinker and his brain oscar and circa the story is wonders the story anyway or past because it feels\n",
            "391/391 [==============================] - 173s 434ms/step - loss: 5.9244\n",
            "Epoch 2/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 5.4539== Generating with temperature 0.2\n",
            "This movie is terrible the original with a good the plot i found on the ultimate classic bad its mind that some truly does not even after seeing is few unfunny even unlike this movie is a short in teach frank [UNK] of the rocks it is everything was great show it\n",
            "== Generating with temperature 0.5\n",
            "This movie is an hiring french dream man with a unit period apart from the music natural the good story of the locations of a very comedic actors trying to balance between tom [UNK] e carradine is evident in this movie and sets the modern explosions this accomplishes a group a christian\n",
            "== Generating with temperature 0.7\n",
            "This movie is a stupid that ricci are so impressed by no good ratings this though the [UNK] weapon i wrote is graphic almost developed also very realistic but a [UNK] with the book for this has analyze it all for me which only bad and david annie [UNK] and [UNK] for\n",
            "== Generating with temperature 1.0\n",
            "This movie stars and the movie is a [UNK] of his enough to save it looks that the scene is central white is exactly how we can vernon oh includes it kind of the [UNK] with quarter julia mill who comes through the movie is that he is it really bad acting\n",
            "== Generating with temperature 1.5\n",
            "This movie is studying uninteresting people found in this is a piece of the spain i that of it does anyone of course a kids a film honesty this essential films and art country who [UNK] joan crawford relive doing well made the first the scene that you want was very poor\n",
            "391/391 [==============================] - 168s 428ms/step - loss: 5.4539\n",
            "Epoch 3/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 5.3143== Generating with temperature 0.2\n",
            "This movie seems that this was terrible could you have you know some sequels to be told in the most viewers some nintendo but as each other things they were gonna look at all or may not be a bit heavy 25 viewers pleasantly talking to any film thinking to recommend this\n",
            "== Generating with temperature 0.5\n",
            "This movie was an excellent movie i found the only comedy of my favorite day then said i got saw the time i have to say is one of a cheesy type that it out that promised disgusted before and the unfamiliar is for that [UNK] and amazingly [UNK] hoping that some\n",
            "== Generating with temperature 0.7\n",
            "This movie takes nothing an interesting for a straight plot what happened youll start from there is probably way to run down the old documentary on the film i lost independent conflicts of which states not not get some things jump forward to grasp on the first she made an [UNK] shot\n",
            "== Generating with temperature 1.0\n",
            "This movie is overlooked for those films overall really made its beauty [UNK] avoid the cover adds an accomplished action was not by another of vampires from time acting one this movie the great oneliners in fact one per they beats if you look bears of the title of human ability to\n",
            "== Generating with temperature 1.5\n",
            "This movie was in my advice is on my career my favourite movie in the future movies i saw it is an nancy west hemingway and it it here but it would get me wanting it [UNK] of time i doubt that this one and it at the house i was priscilla\n",
            "391/391 [==============================] - 169s 431ms/step - loss: 5.3143\n",
            "Epoch 4/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 5.2249== Generating with temperature 0.2\n",
            "This movie was made so flawed but unreal one was so much more difficult to take a comedy is so whats in [UNK] its own crafted it was especially the script and [UNK] of life adam 1968 without good for one of emotion what it had a hilariously cute guy who comes\n",
            "== Generating with temperature 0.5\n",
            "This movie is [UNK] but who is probably the things in love life for power is carrying any of the kind of flowers form an american musical flawless which excuse for anyone who cannot darren gardener after a stunning portrayal of love story cry anchor and staging dennis quaid takes place this\n",
            "== Generating with temperature 0.7\n",
            "This movie is a very little film and acted very good ground its my opinion is absolutely atrocious and dark book lackluster laser the few words to spot its final fantasy about a team of the killer who discovers that have any further from the sun and mulholland know that if youre\n",
            "== Generating with temperature 1.0\n",
            "This movie is taught by who is a great song my head this movie should idea of the stick to have been possessed by dan has clearly decide to sound mind for david lynch next film experience of the dvd case they are only attempt the [UNK] with some kills these three\n",
            "== Generating with temperature 1.5\n",
            "This movie has to mention some comments posted comments on this movie starts with a crap was no exception of view footage is it just how the absurd attempt to someone [UNK] both reason that plays was worthless [UNK] and it is very little gem from the plague i find a big\n",
            "391/391 [==============================] - 169s 433ms/step - loss: 5.2249\n",
            "Epoch 5/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 5.1584== Generating with temperature 0.2\n",
            "This movie is a slapstick comedy set in search for that the cbs star folks couldnt be covered by [UNK] that james [UNK] refugees and a brilliant reader ferry bruce dern frank gets his crystal frank arms he just seems easy studio couldve been so he was in him into the sheriff\n",
            "== Generating with temperature 0.5\n",
            "This movie lacked all you probably feeling when fruit shark rock star in a dollar work it seems like a lot of gardens kids [UNK] i mean theres sex hooker with an exciting a collective arch and its sheer 95 minutes i never having familiar brian antics look at least be desired\n",
            "== Generating with temperature 0.7\n",
            "This movie is so grotesque at surf horribly wrong with its interesting to the film proves that on its all bad and was well the only time there while his time does lust why this place at cannes scene he was an almost all the body and dance take something glamorous lifestyles\n",
            "== Generating with temperature 1.0\n",
            "This movie didnt get the story line was the wake up getting [UNK] company of the beginning to be full moon i also being john waters is a guy living in the interesting to the scarecrow gets lousy coming up his house he is from the original proved behind the far away\n",
            "== Generating with temperature 1.5\n",
            "This movie is 2 really made from stadium about the only person i had an actor but billie anderson comes off the series of the son so convincing especially for making the situation at her greeted by robert englund whos never make family man this game could well i loved her line\n",
            "391/391 [==============================] - 170s 435ms/step - loss: 5.1584\n",
            "Epoch 6/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 5.1051== Generating with temperature 0.2\n",
            "This movie is meant absolutely amazing we have to have seen anyone wanting to leave what it just finished it i take my life just watched it was an image yes his father there are in the entire movie at the first meaning of campy trying to place in south park andrea\n",
            "== Generating with temperature 0.5\n",
            "This movie couldnt have been better see sick like cringing in those responsible for those who needs to be great deal with reallife [UNK] objects and than 20 to make even if you expect i use effects and thats the scores such effort try the coen brothers do believe that good for\n",
            "== Generating with temperature 0.7\n",
            "This movie is like watching every movie trying to the flight kinski still grainy movie ends if you liked this movie it and all costs even liked it for will be enjoyable all the major movie rolled in a bit part as no 1 for a girls school [UNK] and engrossing part\n",
            "== Generating with temperature 1.0\n",
            "This movie is like a traumatized [UNK] austin [UNK] movie it truly happen to me a movie follows the end if you find its just spend the story it was really only [UNK] ie what the actress [UNK] cat in the plot [UNK] makes you just hollywood filmed and you in the\n",
            "== Generating with temperature 1.5\n",
            "This movie is so awesome not true statements about so rich girl and her work that love all that only getting carried over i watched this movie and her true when i hate this movie i would love her soul that played up there are never have to mine to go right\n",
            "391/391 [==============================] - 169s 433ms/step - loss: 5.1051\n",
            "Epoch 7/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 5.0611== Generating with temperature 0.2\n",
            "This movie should be one with the courage of the [UNK] from that john [UNK] between jerry springer technique as the other [UNK] this is so incest come to a much breakdown the yuen [UNK] and of what adventure space candidates the marvelous job but this films shouldnt be little known as\n",
            "== Generating with temperature 0.5\n",
            "This movie essentially just total saturated and 2 [UNK] stuttering plot line and get the only thing lies a truly the characters are laughable and emotion it is really annoying the dialog has to watch movies being so [UNK] gags are hokey to jump from beginning gary daniels and [UNK] down to\n",
            "== Generating with temperature 0.7\n",
            "This movie is first let me say ok i never quite a review in the summary cover wasnt until my attention it and thought it i was a better than all the best thing the location in it i dont mind of the entire film id go check out why because its\n",
            "== Generating with temperature 1.0\n",
            "This movie was hard and this was a waste your time it wasnt getting this was crappy and it belongs with names to watch and the worst was utter the scene to put 1 i ever so something walking by watching it wasnt really the story and started on the only time\n",
            "== Generating with temperature 1.5\n",
            "This movie was flat and unconvincing by me i think director eastwood wrote in and i did read raging correct the only subsequent episodes i feel the director i think dont think god i wasnt anything away in this movie was a bit to speak for hours on it being fan of\n",
            "391/391 [==============================] - 170s 434ms/step - loss: 5.0611\n",
            "Epoch 8/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 5.0232== Generating with temperature 0.2\n",
            "This movie is probably one of my favorite movies ive not a few years ago and since i saw junk it has been making easily appreciate i would be one of the past free love story of the best films that has a great flaws this movie it this is god what\n",
            "== Generating with temperature 0.5\n",
            "This movie gives us in the subject mississippi very endearing and uptight in the period of the film is not 36 year old sugar as the big [UNK] amazing especially from the following the granddaughter of a job and japanese historic ability however due to the film is in the photography because\n",
            "== Generating with temperature 0.7\n",
            "This movie was nice to have been diehard [UNK] and i am still i miss paltrow with the final [UNK] city to play is my attention spans most unknown while this is representative of the western cd now and i thought im pretty good and my particular its borderline piece of this\n",
            "== Generating with temperature 1.0\n",
            "This movie has rare terrorists are divided over because now i paid plenty of those who dislike the genre flicks yet theres no deep story has a traffic to tear by hitchcocks best but boy and comparisons anyway to behold the antics which happen we are almost becomes annoying ridiculous movie which\n",
            "== Generating with temperature 1.5\n",
            "This movie has daylight it is made badly written on the book by only real time mark [UNK] of this film i remembered in a fraction of the event btw but it is involved in this movie like zombies and the first 10 days the film it is about war and your\n",
            "391/391 [==============================] - 170s 435ms/step - loss: 5.0232\n",
            "Epoch 9/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.9892== Generating with temperature 0.2\n",
            "This movie is a good drama that builds upon opening involving necessarily a bare victims are equally bizarre lead badly executed entry in an unstoppable [UNK] and interview with southern boot that reaches out to portray a bunch and [UNK] in graphic horror [UNK] garrett michelle government area especially after the dangers\n",
            "== Generating with temperature 0.5\n",
            "This movie was so dumb to explain why in to name pitch to 4 hours of just a cast stand down with the frame in this role easily be nothing to me i assure you see where did not acting however darkness at least it starts as i can shoot this again\n",
            "== Generating with temperature 0.7\n",
            "This movie relies first off by itself is often you the dvd it and doesnt look if i got a good director christopher walken in los angeles since then the mud was able to anyone who saw this good qualities because he loves it low standards but i went into something flaw\n",
            "== Generating with temperature 1.0\n",
            "This movie is amazing graphics and 90s action suspense there are old flying cheap horror and brit flicks and thats really hard to let down i have to say that you just think any meaning that made worthy of not just one stands fried alive zombie beowulf gore is no budget and\n",
            "== Generating with temperature 1.5\n",
            "This movie is terrible no i reckon gears in many gags shame about every one thats why is beginning it on that when it turns out of the story twists left me cheer you watch it fails on what an incredibly boring that one of meryl streep has a guy show almost\n",
            "391/391 [==============================] - 170s 435ms/step - loss: 4.9892\n",
            "Epoch 10/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.9594== Generating with temperature 0.2\n",
            "This movie is so lame and other info as funny i have watched this one as the plot sucked the language gives me up terrible henry manages can get the drama standards if the parts a kid antonio [UNK] calm an imdb of the same old saying wait and for kids laughed\n",
            "== Generating with temperature 0.5\n",
            "This movie totally has everything like it isnt bad that you just bad it is now but i really really can be bad in such a very entertaining it moves so over independent low grade this story about ten minutes the date the swear that makes more than worth seeing [UNK] the\n",
            "== Generating with temperature 0.7\n",
            "This movie is simple it has a strange dream i love you get the fact it yes i think if i totally amused by [UNK] to be a kind of all but enough to see it this one it is a movie if i saw it has a movie for so much\n",
            "== Generating with temperature 1.0\n",
            "This movie contains originally done by likely got my teenage girls they were those of our prince who didnt connect with her [UNK] wronged just welcomed women not have left in the wedding in it was secretly test of the [UNK] bus with the area is called for 1980 but they were\n",
            "== Generating with temperature 1.5\n",
            "This movie reminded me a point where this is so much that the movie is actually kind of [UNK] by me instantly forgettable stuff the early 50s and terrifying fury did entertain kids enjoyed it because it funny will love this now [UNK] cause your own it gives a very little erotic\n",
            "391/391 [==============================] - 170s 434ms/step - loss: 4.9594\n",
            "Epoch 11/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.9324== Generating with temperature 0.2\n",
            "This movie still i thought it takes more combining more confusing and interesting dimension than this movie has the books its audience with the cad then you wish had started out that feeling slow pace but that appear as we have anything the modern day the characters that adds nothing at points\n",
            "== Generating with temperature 0.5\n",
            "This movie in my pitch 1981 was devoid of churning consideration for me as much luck he wai plays by harvey keitel creates a rope and a [UNK] is a ruthless black dress on a [UNK] 2000 years old flame most criminal but this one child and has been drawn by eric\n",
            "== Generating with temperature 0.7\n",
            "This movie really combines an icon christian bale said irish sheriff runner that the word his childhood friend he wanted his spine he and [UNK] [UNK] and i could have the banter will engage in a bad guy vampires this stinker the screaming he could [UNK] dollars so what shot him out\n",
            "== Generating with temperature 1.0\n",
            "This movie has nothing to be said it was made it is essentially boring the plot that perception of snippets of cool and when the writers run crushed over 60 minutes of pure genius as lord of a writer who had been made this movie the actors achieve them this could marry\n",
            "== Generating with temperature 1.5\n",
            "This movie was pretty good because i am glad it should be realistic and stupid absurd the art idiotic cliché comedy the video box had no serious lack of mate i should be married lover more positive about [UNK] jobs and disjointed music [UNK] it all about creative believability no [UNK] minor\n",
            "391/391 [==============================] - 170s 434ms/step - loss: 4.9324\n",
            "Epoch 12/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.9068== Generating with temperature 0.2\n",
            "This movie stars a dutch play out and i almost forgot office anniversary of all generations but just have one [UNK] it gets a must admit i dont like watching a person who has crafted my [UNK] movie is perfect its storyline is supposedly horrible disaster nightmare to know it constantly [UNK]\n",
            "== Generating with temperature 0.5\n",
            "This movie is surprised with human the characters have a people are in this film is a very nice movie is genius and the movie is terrific especially experimental the other in movie computer generated back to play cars and [UNK] combat in all the only it is a [UNK] people thats\n",
            "== Generating with temperature 0.7\n",
            "This movie is ridiculous the incredible old you have to believe the worst movie is that the movie there is that i have seen i have seen in a huge spy movies that it is horrible you cant help this is supposed to the plot is the even for one you in\n",
            "== Generating with temperature 1.0\n",
            "This movie does have something i do with rupert [UNK] job of my wife as brenda [UNK] that after [UNK] directed the list them on a team living in regards julie ryan throughout but what makes a sappy country whoever made me at a business man outside the ships for music eerily\n",
            "== Generating with temperature 1.5\n",
            "This movie is so [UNK] can be sick fun yourself i dont understand why arent fun its so cute and fun you can find it is perfect images but really adults are invited to throw yourself so i love it is not the only store and bad but you make due right\n",
            "391/391 [==============================] - 170s 434ms/step - loss: 4.9068\n",
            "Epoch 13/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.8836== Generating with temperature 0.2\n",
            "This movie is worth to [UNK] watching causing exercise in [UNK] immediately at 90 minutes you [UNK] film and [UNK] by allen a decent conclusion word this tries to clean shots you guessed it in a [UNK] of hostel etc one points the evidence that feeling so it so it the cinematography\n",
            "== Generating with temperature 0.5\n",
            "This movie is absolutely awful i have to be [UNK] then it is not new characters and unrealistic you can be a censored two best but dont bother [UNK] and every frame of [UNK] it tries to ask yourself wanting for the acting is horrendously [UNK] regular the movie which appeals to\n",
            "== Generating with temperature 0.7\n",
            "This movie is not too good in my opinion but which is not only as it is [UNK] it is for the score is boring and not for canadian and several dollars it rates as it is pretty but for usually not the basic you ever seen in minority to [UNK] movie\n",
            "== Generating with temperature 1.0\n",
            "This movie is based on the darkness of the classic the book that the story was great disappointment and every stupid and how not seen it gets into the movie completely absent even if you would then broken political stereotypes except the book nobody presented thanks to it is great robert duvall\n",
            "== Generating with temperature 1.5\n",
            "This movie was a youth with questions questions and questions and moments intact to achieve a historian or focused [UNK] was it had huge depth there are left me the loyalty differences between the throws the environment for us about circumstances stages of satisfaction that there was wanting to me i can\n",
            "391/391 [==============================] - 170s 434ms/step - loss: 4.8836\n",
            "Epoch 14/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.8620== Generating with temperature 0.2\n",
            "This movie begins a sensitive student mitch a [UNK] [UNK] is told to be certain amount of everyday thoughts and already the story keeps the helpless to move into [UNK] of people they continue loving and not mentally disturbed by [UNK] behavior from some people got their uncle was hoping for example\n",
            "== Generating with temperature 0.5\n",
            "This movie followed by frame the special effect contains a 0 before purchasing on imdb its not kidding you far too much which apply you or you get scared to realize that time dont have a larry [UNK] it is directed by being beaten and [UNK] in theme tune with the genre\n",
            "== Generating with temperature 0.7\n",
            "This movie is mostly with have every cliché things that the villains some funny this show and john glover delivers obtained as everyone we have seen eddie seen other and jade leung is very well as [UNK] liar liar noticed kids werent for him according to become [UNK] dressed as his dog\n",
            "== Generating with temperature 1.0\n",
            "This movie was laughably terrible the person doing battle images of the color [UNK] fathers death wish to the religious credible i have already ineffectual comet over if you wont be acting wouldbe russian officer and asked to some form said this is now they read all had some sort of these\n",
            "== Generating with temperature 1.5\n",
            "This movie had me unfortunate intelligence of seeing i saw this movie when i noticed that it sounds like billy crystal and [UNK] if i had with all mouth came all the original and the casts pictures looking forward to expect but im not the public movies based on part in a\n",
            "391/391 [==============================] - 170s 434ms/step - loss: 4.8620\n",
            "Epoch 15/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.8413== Generating with temperature 0.2\n",
            "This movie is [UNK] allen during the times not in the top 10 mob or blatant accents this role of clumsy ones [UNK] basement he rest in a bit to [UNK] [UNK] the latter category robert newton dr [UNK] gross adventure movie has killed plausibility [UNK] the occurrences but shes really any\n",
            "== Generating with temperature 0.5\n",
            "This movie was a [UNK] of the xfiles most successful travesty the first and [UNK] wes craven [UNK] nest of a band called a [UNK] from [UNK] [UNK] as [UNK] and [UNK] shots a most successful [UNK] and the chinese [UNK] [UNK] [UNK] were from the corny by showing steve [UNK] on\n",
            "== Generating with temperature 0.7\n",
            "This movie was made for hollywood in the worst one of four stories ever made the movie preceded by leslie [UNK] santa claus the [UNK] and that movie team up against the writers and financial weapon which were the recent times better and judge leading to become slugs there is definitely brought\n",
            "== Generating with temperature 1.0\n",
            "This movie is simply [UNK] its a romance but it should never succeeds by anybody who wants to successful again at his life worse still keeps you say you count the stunning for the only difference a husband of the mail order to defeat him is really bad guys at the banter\n",
            "== Generating with temperature 1.5\n",
            "This movie fails miserably the actors arent delivered with this inherently terrible the acting were all combined and the plot is the fare no line or 9 from a comedy in the story was quite as were hard to work without merit any [UNK] the defining there are holes bad accents this\n",
            "391/391 [==============================] - 170s 434ms/step - loss: 4.8413\n",
            "Epoch 16/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.8220== Generating with temperature 0.2\n",
            "This movie was like how stupid i turned to be a fairly lowbudget movies i have ever seen in my life i cant even after watching it and jokes that they came out loud and i can handle the black white man etc i think america down to see a film again\n",
            "== Generating with temperature 0.5\n",
            "This movie is a well known lowbudget [UNK] [UNK] scare fame [UNK] conventions of young mans epic django and intense and is the evil and the story of [UNK] who encounters with a [UNK] couple living there director sergio [UNK] [UNK] and menace as an ignorant alien [UNK] it also offers the\n",
            "== Generating with temperature 0.7\n",
            "This movie was one of several parallel though it is strange people now lives a crime why people can kill people the same self obsessed with the script writer director of the story producers know  is for yet you i in for so follows 12 [UNK] and chris tv was on\n",
            "== Generating with temperature 1.0\n",
            "This movie is a remake of the better than [UNK] will deny in 2000 not be silly but is a sequel in its score is a classic and there have 100 better than this film imagine that what you can imagine a dull teen slasher movie the terrible this shouldnt fail to\n",
            "== Generating with temperature 1.5\n",
            "This movie appeared as a [UNK] movie was that was entirely believable and was by martin sheen michael [UNK] would have thought i could improve on all worth it was no plot was convincing just poor ned [UNK] the dialogue sounds like the movie was definitely given to be boring the producers\n",
            "391/391 [==============================] - 170s 435ms/step - loss: 4.8220\n",
            "Epoch 17/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.8033== Generating with temperature 0.2\n",
            "This movie is so unique in the 1970s is my subject and its a vast improvement on how can get even taken by its a group of upper society as the kind of the notion of life in one of [UNK] curious people are almost red journey into what kind of the\n",
            "== Generating with temperature 0.5\n",
            "This movie horse crisis is annoying yoda [UNK] every scene annette [UNK] can show a nice music is annoying and annoying or binoche is terrible it could ever a strange physically agreed to be that bad here in the good rating everyone loves other things the show ok im not bothering with\n",
            "== Generating with temperature 0.7\n",
            "This movie is a accurate portrayal of [UNK] was pathetic piece of russian language and as regards to watch gone i considering the permanent london to watch all in china syndrome prostitution by nature from silence and womens errors that we were men wearing for class i should see [UNK] tough that\n",
            "== Generating with temperature 1.0\n",
            "This movie is a milestone b movie or so poor in english that is one person sell you might want to see what if youre getting married to play one more than harmony within a prostitute to comment is truly powerful action films wish you say the majority warn you are greek\n",
            "== Generating with temperature 1.5\n",
            "This movie is hilarious it took my favorite we got to our basketball days from how funny is he produces at the funny got around one night while i sometimes said out of war games funny until only funny rob [UNK] my top of his family look at the gilmore is soon\n",
            "391/391 [==============================] - 170s 435ms/step - loss: 4.8033\n",
            "Epoch 18/200\n",
            "188/391 [=============>................] - ETA: 1:23 - loss: 4.7908"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ed4ff86120ee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_gen_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.fit(lm_dataset, epochs=200, callbacks=[text_gen_callback])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "chapter12_part01_text-generation.i",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}