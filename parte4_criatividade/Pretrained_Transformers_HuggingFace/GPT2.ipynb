{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNqAn+16I6zZi82hOnXiJrA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luiscunhacsc/udemy-ia-pt/blob/main/GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Suprimir avisos (para tornar saída mais limpa)\n",
        "# Estamos a usar modelos públicos, pelo que não é preciso autenticar-nos\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "metadata": {
        "id": "F_wj4_AuAqt_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar as bibliotecas necessárias\n",
        "!pip install -q transformers torch"
      ],
      "metadata": {
        "id": "SqCmEZ4M8fCH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "\n",
        "model_name = 'gpt2'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name).to('cuda')"
      ],
      "metadata": {
        "id": "MvcpJlp_8hFU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SA593vkw6y4K"
      },
      "outputs": [],
      "source": [
        "# Função para geração de texto\n",
        "\n",
        "import time\n",
        "\n",
        "def generate_text(prompt, model, tokenizer, max_length=100, temperature=0.7):\n",
        "    inputs = tokenizer.encode(prompt, return_tensors='pt').to('cuda')\n",
        "    attention_mask = torch.ones(inputs.shape, dtype=torch.long).to('cuda')\n",
        "\n",
        "    # Medir o tempo de geração\n",
        "    start_time = time.time()\n",
        "    outputs = model.generate(inputs,\n",
        "                             attention_mask=attention_mask,\n",
        "                             max_length=max_length,\n",
        "                             temperature=temperature,\n",
        "                             num_return_sequences=1,\n",
        "                             do_sample=True,\n",
        "                             top_k=50,\n",
        "                             pad_token_id=tokenizer.eos_token_id)  # Definir explicitamente o pad_token_id\n",
        "    end_time = time.time()\n",
        "\n",
        "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    generation_time = end_time - start_time\n",
        "\n",
        "    return text, generation_time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt inicial\n",
        "prompt = \"Once upon a time in Hollywood\"\n",
        "\n",
        "# Geração com diferentes temperaturas\n",
        "for temp in [0.2, 0.7, 1.0]:\n",
        "    print(f\"\\n--- Narrativa com temperatura {temp} ---\")\n",
        "    narrative, gen_time = generate_text(prompt, model, tokenizer, temperature=temp)\n",
        "    print(f\"Tempo de geração: {gen_time:.2f} segundos\")\n",
        "    print(narrative)\n"
      ],
      "metadata": {
        "id": "iPd44l_sGB_0",
        "outputId": "f17c18df-4937-4894-f008-8add3e99242d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Narrativa com temperatura 0.2 ---\n",
            "Tempo de geração: 1.99 segundos\n",
            "Once upon a time in Hollywood, the director of a film was a man who had been a member of the family of a wealthy family. He was a man who had been a member of the family of a wealthy family. He was a man who had been a member of the family of a wealthy family. He was a man who had been a member of the family of a wealthy family. He was a man who had been a member of the family of a wealthy family. He was a man\n",
            "\n",
            "--- Narrativa com temperatura 0.7 ---\n",
            "Tempo de geração: 0.90 segundos\n",
            "Once upon a time in Hollywood, the idea of a young actor being cast for the big screen was something that had been a little more taboo until suddenly the new generation had become very popular. The idea that this kind of thing was going to happen was really something that had been a little bit taboo until suddenly the new generation had become very popular.\n",
            "\n",
            "--- Narrativa com temperatura 1.0 ---\n",
            "Tempo de geração: 1.59 segundos\n",
            "Once upon a time in Hollywood he came to one of the very first houses in Hollywood's history called Hollywood Studios and had his house there built. He said that this was where, of all of the American cities all over America, he got his idea of a scene when he did a scene on the first scene which was with a guy from New York. And I like to call this one Scene. Where everybody is like, \"Yeah, this is where I'm going to meet the best actress in\n"
          ]
        }
      ]
    }
  ]
}